{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fa4f97",
   "metadata": {},
   "source": [
    "# hs-code-nlp-classifier-cl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803b18d",
   "metadata": {},
   "source": [
    "## Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58812ba",
   "metadata": {},
   "source": [
    "### Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0630f3a6",
   "metadata": {},
   "source": [
    "- El Servicio Nacional de Aduanas de Chile aporta cerca del 30% de los impuestos que financian el desarrollo del país. \n",
    "- La correcta clasificación (código arancelario) es clave para: a) Cálculo de Aranceles, b) Aplicación de Tratados de Comercio, y  c) Cumplimiento Normativo.\n",
    "- Estándar Global con Aplicación Local: se utiliza el Sistema Armonizado (HS), un estándar mundial (95% de adherencia) que requiere de ajustes y jurisprudencia local específicos de Chile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad375ad0",
   "metadata": {},
   "source": [
    "### Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701a45fa",
   "metadata": {},
   "source": [
    "- El Desafío de Clasificar: un proceso manual, específico y dinámico.\n",
    "- Proceso manual e intenso (tedioso) realizado por operadores humanos (conocimiento experto, sistemas informáticos para registro) de Agencias de Aduana. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd571d",
   "metadata": {},
   "source": [
    "### Relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9227aef5",
   "metadata": {},
   "source": [
    "- El error genera riesgo de multas/pérdida de tiempo en correcciones para las Agencias de Aduanas y Operadores de Comercio Exterior, y pérdida de recaudación para Aduanas Chile, afectando la calidad del servicio de las agencias. \n",
    "- Incumplimiento normativo (las multas afectan a la agencia de aduanas), también puede existir un tiempo de clasificación alto, afectando al cliente y al equipo humano de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d15ac7d",
   "metadata": {},
   "source": [
    "## Configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e263bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, classification_report, confusion_matrix\n",
    "\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    set_seed,\n",
    ")\n",
    "import gc\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_proyecto = Path.cwd()\n",
    "path_src = path_proyecto / \"src\"\n",
    "if str(path_src) not in sys.path:\n",
    "    sys.path.append(str(path_src))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e420de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.utils import *\n",
    "from src.csv import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5fc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "crear_carpetas()\n",
    "DIR_RAW_DATA = obtener_path(\"raw\")\n",
    "DIR_IMAGES = obtener_path(\"images\")\n",
    "DIR_OUTPUTS = obtener_path(\"outputs\")\n",
    "DIR_MODELS = obtener_path(\"models\")\n",
    "DIR_LOG = obtener_path(\"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30807174",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = obtener_seed()\n",
    "print(f\"[INFO] Seed usada: {SEED}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924ad1f0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b2863f",
   "metadata": {},
   "source": [
    "### Carga Datos Etiquetados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2454f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] Dispositivo:\")\n",
    "print(f\" - torch.backends.mps.is_available(): {torch.backends.mps.is_available()}\")\n",
    "print(f\" - torch.backends.mps.is_built(): {torch.backends.mps.is_built()}\")\n",
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\" - torch version: {torch.__version__}\")\n",
    "print(f\" - device seleccionado: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f665331",
   "metadata": {},
   "outputs": [],
   "source": [
    "CVV_FILENAME = \"mercancias20260111_004347.csv\"\n",
    "\n",
    "raw_df = cargar_csv(Path(DIR_RAW_DATA, CVV_FILENAME))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973728ac",
   "metadata": {},
   "source": [
    "### Exploración"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a4ef3",
   "metadata": {},
   "source": [
    "#### Características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27340fd6",
   "metadata": {},
   "source": [
    "**Columnas:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2db264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Columnas del Dataset: {raw_df.columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700bc137",
   "metadata": {},
   "source": [
    "**Muestra de registros**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531a6226",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.sample(10, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69949384",
   "metadata": {},
   "source": [
    "**WordCloud**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85ff9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc_cache_image = \"wordcloud-raw-data.png\"\n",
    "wc_cache_path = Path(DIR_IMAGES, wc_cache_image)\n",
    "\n",
    "if wc_cache_path.exists():\n",
    "    img = Image.open(wc_cache_path)\n",
    "else:\n",
    "    text = \" \".join(\n",
    "        raw_df[\"mercancia_descripcion\"]\n",
    "        .fillna(\"\")\n",
    "        .astype(str)\n",
    "        .tolist()\n",
    "    )\n",
    "    wc = WordCloud(width=1000, height=500, background_color=\"white\").generate(text)\n",
    "    img = wc.to_image()\n",
    "    img.save(wc_cache_path)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.imshow(np.array(img), interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2991021",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- La nube muestra que las descripciones están dominadas por términos de uso y destino (“PARA”, “USO”, “PARTE”, “DE”), además de categorías de producto frecuentes como “VEHICULO”, “ACERO”, “SANDVIK”, “TEJIDO”, “PIEZA”. Esto sugiere un lenguaje muy estandarizado y orientado a “para X”, lo que puede introducir stopwords específicas del dominio (ej. “para”, “de”, “uso”) que quizá conviene filtrar en modelos VCM para resaltar términos más discriminantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409480d",
   "metadata": {},
   "source": [
    "#### Datos no válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_vacias = (\n",
    "    raw_df[\"mercancia_descripcion\"]\n",
    "    .fillna(\"\")\n",
    "    .str.strip()\n",
    "    .eq(\"\")\n",
    "    .sum()\n",
    ")\n",
    "print(\"[INFO] Registros con descripción vacía:\", desc_vacias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar registros con descripción vacía o solo espacios\n",
    "data_df = raw_df[\n",
    "    raw_df[\"mercancia_descripcion\"]\n",
    "    .fillna(\"\")\n",
    "    .str.strip()\n",
    "    .ne(\"\")\n",
    "].copy()\n",
    "\n",
    "print(\"[INFO] Info dataset:\")\n",
    "print(\" - Registros totales:\", len(raw_df))\n",
    "print(\" - Registros tras limpieza:\", len(data_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ce8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"len_descripcion\"] = (\n",
    "    data_df[\"mercancia_descripcion\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.len()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6cdc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[\"len_descripcion\"].describe(percentiles=[0.5, 0.75, 0.9, 0.95, 0.99])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09680632",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- Se analizaron **5,125,025** descripciones.\n",
    "- La longitud promedio es **~53 caracteres** y la mediana es **50**, lo que indica textos relativamente cortos.\n",
    "- El **75%** de las descripciones tiene **≤63 caracteres**.\n",
    "- El **90%** está bajo **80 caracteres**, y el **95%** bajo **90**.\n",
    "- El **99%** no supera **116 caracteres**; el máximo observado es **180**.\n",
    "\n",
    "**Conclusión:** la mayoría de las descripciones son muy breves. Para BERT, un `max_length` de **128** sería suficiente para cubrir casi todo el universo sin truncar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127c8b9a",
   "metadata": {},
   "source": [
    "#### Frecuencias de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e28d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_filas = data_df[\"partida_arancelaria_codigo\"].notna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86351136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frecuencia de todas las clases\n",
    "\n",
    "raw_freq_df = data_df[\"partida_arancelaria_codigo\"].value_counts()\n",
    "raw_freq_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bd6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de clases (frecuencia)\n",
    "\n",
    "raw_freq_df.describe(percentiles=[0.25, 0.5, 0.75, 0.9, 0.95, 0.99])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3bfbc0",
   "metadata": {},
   "source": [
    "**notas**\n",
    "- Se identifican **5.597 clases** distintas.\n",
    "- La mediana es 51: la mitad de las clases tiene 51 registros o menos.\n",
    "- El **25% de las clases** tiene **9 registros o menos**, lo que indica presencia de muchas clases poco representadas.\n",
    "- El 75% tiene ≤292 registros.\n",
    "- Solo el 10% supera ~1.381 registros.\n",
    "- El 1% supera ~17.474 registros.\n",
    "- El máximo es 126.200, alto contraste.\n",
    "- Conclusiones: \n",
    "  - Hay muchas clases con muy pocos ejemplos y pocas clases dominantes. \n",
    "  - Es posible que se deba limitar clases más representadas o agrupar clases poco frecuentes en `OTHER`.\n",
    "- Para modelar, se puede explorar algunas técnicas:\n",
    "  - Limitar a las clases más frecuentes\n",
    "  - Definir etiqueta OTHER para agrupar las poco representadas\n",
    "  - Aplicar técnicas de balanceo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f41b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de cobertura por top N clases\n",
    "\n",
    "total = raw_freq_df.sum()\n",
    "\n",
    "for n in [5, 10, 20, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "    topn = raw_freq_df.head(n)\n",
    "    rest = raw_freq_df.iloc[n:]\n",
    "    prop_top = topn.sum() / total * 100\n",
    "    prop_rest = rest.sum() / total * 100\n",
    "    print(f\"Top {n:4d}: {topn.sum():>10} ({prop_top:6.2f}%) | Resto: {rest.sum():>10} ({prop_rest:6.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7671c113",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- La distribución está fuertemente concentrada: **Top 5** ya cubre **10%** del total.\n",
    "- Con **Top 10** se cubre **18%**, menos de una quinta parte del universo.\n",
    "- Al llegar a **Top 50**, se cubre **42%**; es decir, más de la mitad sigue en “resto”.\n",
    "- El **Top 100** cubre **55%** y el **Top 200** alcanza **67%**.\n",
    "- Para superar el **80%** de cobertura se necesitan alrededor de **400 clases** (79%) a **500 clases** (82%).\n",
    "- Para cobertura alta, el número de clases objetivo debe ser grande (≈400–500 para >80%). \n",
    "- Para un modelo más acotado, conviene usar `OTHER` para el resto o limitarse a un Top‑N más pequeño con una cobertura aceptada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestra de clases más representadas\n",
    "\n",
    "n = 20\n",
    "raw_clases_top_n = (\n",
    "    data_df[\"partida_arancelaria_codigo\"]\n",
    "    .value_counts()\n",
    "    .head(n)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"partida_arancelaria_codigo\", \"partida_arancelaria_codigo\": \"frecuencia\"})\n",
    ")\n",
    "\n",
    "raw_clases_top_n[\"porcentaje_total\"] = (raw_clases_top_n[\"count\"] / total_filas) * 100\n",
    "raw_clases_top_n[\"porcentaje_total\"] = raw_clases_top_n[\"porcentaje_total\"].map(lambda x: f\"{x:.2f}%\")\n",
    "\n",
    "raw_clases_top_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1efde7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases con muy baja representación (umbral)\n",
    "\n",
    "umbral = 500\n",
    "clases_poco_representadas = raw_freq_df[raw_freq_df < umbral]\n",
    "\n",
    "print(\"[INFO] Clases con < umbral() :\", len(clases_poco_representadas))\n",
    "clases_poco_representadas.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ec93bc",
   "metadata": {},
   "source": [
    "**Notas**\n",
    "- El resultado indica que 4.534 clases tienen menos de 500 registros (según umbral). \n",
    "- En el extracto se ve que muchas están justo cerca del límite (490–499), lo que sugiere una larga cola de clases poco representadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069a5b08",
   "metadata": {},
   "source": [
    "**Criterio máxima curvatura sobre cobertura vs umbral**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce74872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbrales automáticos en log-escala para cubrir bien rangos bajos/medios\n",
    "\n",
    "print(\"[INFO] Selección automática de umbral - Criterio máxima curvatura sobre cobertura vs umbral\")\n",
    "min_t = max(1, int(raw_freq_df.min()))\n",
    "max_t = int(raw_freq_df.max())\n",
    "thresholds = np.unique(np.round(np.logspace(np.log10(min_t), np.log10(max_t), 40)).astype(int))\n",
    "\n",
    "coverage = []\n",
    "for t in thresholds:\n",
    "    keep = raw_freq_df[raw_freq_df >= t]\n",
    "    coverage.append(keep.sum() / total_filas * 100)\n",
    "\n",
    "# Curvatura numérica\n",
    "x = np.log10(thresholds.astype(float))\n",
    "y = np.array(coverage)\n",
    "\n",
    "x_norm = (x - x.min()) / (x.max() - x.min())\n",
    "y_norm = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "curvature = np.abs(np.gradient(np.gradient(y_norm, x_norm), x_norm))\n",
    "knee_idx = int(np.argmax(curvature))\n",
    "knee_t = thresholds[knee_idx]\n",
    "knee_cov = coverage[knee_idx]\n",
    "\n",
    "print(\" - Umbral recomendado (knee):\", knee_t)\n",
    "print(\" - Cobertura en ese umbral:\", f\"{knee_cov:.2f}%\")\n",
    "print(\" - Clases que cumplen umbral:\", int((raw_freq_df >= knee_t).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66179f65",
   "metadata": {},
   "source": [
    "**Criterio mínimo N que alcance 80–90% del total**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a74932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de cobertura por porcentaje total\n",
    "\n",
    "targets = [0.50, 0.60, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95]\n",
    "cum = raw_freq_df.cumsum() / raw_freq_df.sum()\n",
    "for target in targets:\n",
    "    n = (cum <= target).sum() + 1\n",
    "    print(f\"% Representación del {target:.2f} total: {n} clases\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd60793",
   "metadata": {},
   "source": [
    "**Criterio Mínimo por split**: asegurar al menos X ejemplos en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668782c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral basado en número de muestras en test set\n",
    "\n",
    "test_size = 0.2\n",
    "min_tests = [60, 80, 120, 150, 250, 300, 400, 500, 600, 700, 800]\n",
    "\n",
    "for min_test in min_tests:\n",
    "    min_muestras = int(min_test / test_size)\n",
    "    classes_keep = raw_freq_df[raw_freq_df >= min_muestras].index\n",
    "    print(f\"min_test {min_test:4d} -> min_muestras {min_muestras:5d} -> clases {len(classes_keep)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82704a89",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- mínimo por split (min_test) vs clases retenidas\n",
    "  - A mayor `min_test`, mayor `min_muestras` requerido por clase, por lo que disminuye el número de clases que cumplen el umbral.\n",
    "  - Con **min_test=60–150** (300–750 muestras por clase) aún se conservan **~860–1,385 clases**, un conjunto amplio.\n",
    "  - Con **min_test=250–400** (1,250–2,000 por clase) el conjunto baja a **~432–609 clases**, un rango más manejable.\n",
    "  - Con **min_test=600–800** (3,000–4,000 por clase) quedan **~222–299 clases**, priorizando estabilidad y calidad de entrenamiento.\n",
    "\n",
    "**Conclusión**: \n",
    "- Para un clasificador con alta precisión y clases bien representadas, un rango útil sería **min_test 250–500** (≈350–600 clases). \n",
    "- Si se requiere más estabilidad por clase, se puede aumentar a **min_test 600+**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c61fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proporción acumulada de frecuencias:\n",
    "raw_freq_df = raw_freq_df.sort_values(ascending=False)\n",
    "cum = raw_freq_df.cumsum() / raw_freq_df.sum()\n",
    "\n",
    "# Clases que cubren x% del total (umbral de cobertura acumulada\n",
    "cutoffs = [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "for cutoff in cutoffs:\n",
    "    classes_keep = cum[cum <= cutoff].index\n",
    "    print(f\"Cutoff {cutoff:.2f}: {len(classes_keep)} clases\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67244306",
   "metadata": {},
   "source": [
    "**Notas**;\n",
    "\n",
    "- **Interpretación de clases necesarias por cobertura (cutoff)**:\n",
    "  - **50% de cobertura** requiere **74 clases**.\n",
    "  - **60%** requiere **132 clases**.\n",
    "  - **70%** requiere **234 clases**.\n",
    "  - **75%** requiere **312 clases**.\n",
    "  - **80%** requiere **420 clases**.\n",
    "  - **85%** requiere **572 clases**.\n",
    "  - **90%** requiere **816 clases**.\n",
    "  - **95%** requiere **1,295 clases**.\n",
    "- **Conclusión**: \n",
    "  - La cobertura crece rápido al inicio, pero a partir de 80% el número de clases aumenta de forma acelerada.\n",
    "  - Confirma una distribución altamente dispersa. \n",
    "  - 70–85% suele ser un buen rango de compromiso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12419ac1",
   "metadata": {},
   "source": [
    "**Umbral vs Clases y Cobertura**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92be9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar umbrales\n",
    "thresholds = [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000, 3000, 4000, 5598]\n",
    "\n",
    "n_classes = []\n",
    "coverage = []\n",
    "\n",
    "for t in thresholds:\n",
    "    keep = raw_freq_df[raw_freq_df >= t]\n",
    "    n_classes.append(len(keep))\n",
    "    coverage.append(keep.sum() / total_filas * 100)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12,4))\n",
    "ax1.plot(thresholds, n_classes, marker=\"o\", label=\"Clases cumplen umbral\")\n",
    "ax1.set_xlabel(\"min_muestras por clase\")\n",
    "ax1.set_ylabel(\"Número de clases\")\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(thresholds, coverage, marker=\"s\", color=\"orange\", label=\"Cobertura (%)\")\n",
    "ax2.set_ylabel(\"Cobertura del total (%)\")\n",
    "\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines + lines2, labels + labels2, loc=\"best\")\n",
    "\n",
    "plt.title(\"Selección de umbral: clases vs cobertura\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00077e95",
   "metadata": {},
   "source": [
    "**Notas:**\n",
    "- A medida que aumenta `min_muestras` por clase, disminuye el `número de clases` que cumplen el umbral.\n",
    "- La **cobertura total** cae de forma gradual: \n",
    "  - Con umbrales bajos se mantiene alta, pero se reduce al exigir más ejemplos por clase.\n",
    "- Se observa un **trade‑off claro**: \n",
    "  - Umbrales bajos permiten muchas clases pero con menor calidad/estabilidad\n",
    "  - Umbrales altos priorizan clases bien representadas pero reducen la cobertura.\n",
    "- El “punto de equilibrio” visual parece estar entre **1,000 y 2,000 muestras por clase**, donde aún hay cientos de clases y una cobertura razonable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5291bd85",
   "metadata": {},
   "source": [
    "### Definiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd15c0d",
   "metadata": {},
   "source": [
    "**Información**:\n",
    "- Registros totales: 5.136.897\n",
    "- Registros tras limpieza: 5.125.025 (se excluyen, por ejemplo, descripciones vacías: 11.872)\n",
    "- **Variable objetivo**: partida_arancelaria_codigo (códigos tipo 8 dígitos, p. ej. 30061059)\n",
    "- **Desbalance crítico**: con un umbral de 500 muestras por clase, hay 4.534 clases bajo ese mínimo (colas largas).\n",
    "- La distribución está dominada por pocas clases (las más frecuentes superan 100k ocurrencias), mientras muchas clases aparecen pocas centenas de veces.\n",
    "\n",
    "En este contexto, la decisión clave para maximizar éxito (accuracy/F1) es definir cuántas clases se intentará predecir (y con qué soporte por clase).\n",
    "\n",
    "\n",
    "**Criterios para definir Umbrales**:\n",
    "1.\tCorte por cobertura acumulada (top-K clases que explican X% del total):\n",
    "    - 0,70 -> 234 clases\n",
    "    - 0,75 -> 312 clases\n",
    "    - 0,80 -> 420 clases\n",
    "    - 0,85 -> 572 clases\n",
    "    - 0,90 -> 816 clases\n",
    "    - 0,95 -> 1295 clases\n",
    "\n",
    "2.\tCorte por mínimo de muestras en test, asumiendo test_size = 0.2 (para que cada clase tenga suficiente evidencia en evaluación):\n",
    "  - **min_test 150** -> min_train+test 750 -> 859 clases\n",
    "  - **min_test 400** -> min_train+test 2000 -> 430 clases\n",
    "  - **min_test 800** -> min_train+test 4000 -> 222 clases\n",
    "\n",
    "3. **Clasificador `SVM`**\n",
    "   - Propuesta: ~300 clases (rango 234–312)\n",
    "     - **Opción principal** (balanceada): 312 clases (cubre ~75% del dataset).\n",
    "     - **Opción alternativa** (menos costo): 234 clases (cubre ~70%).\n",
    "     - **Opción alternativa por soporte estadístico**: ~300 clases si se fija `min_muestras` ≈ 3000 (derivado del análisis min_test/0.2).\n",
    "   - **Justificación técnica**: en multiclase grande, SVM (aun lineal) tiende a degradar más rápido por solapamiento semántico y ruido en descripciones, y además el costo de one-vs-rest crece con #clases. Reducir a ~300 clases suele dar un salto grande en precisión y estabilidad.\n",
    "\n",
    "4) **Clasificador `BERT`**\n",
    "   - Propuesta: ~430–572 clases (recomendación operativa: 430)\n",
    "     - **Opción principal** (mejor trade-off para “alto éxito”): ~430 clases, alineado con `min_muestras` ≈ 2000 (equivale a exigir ~400 ejemplos mínimos en test con test_size=0.2).\n",
    "     - **Opción alternativa**: 572 clases (cubre ~85% del dataset), pero es más exigente: aumentan confusiones entre códigos cercanos y se requiere mejor normalización del texto + más cuidado con entrenamiento (scheduler, epochs, class weights/focal, etc.).\n",
    "   - **Justificación técnica**: BERT captura mejor la semántica y suele sostener desempeño con más clases que SVM, si se incluyen muchas clases raras, la métrica se hunde por falta de ejemplos y por descripciones ambiguas.\n",
    "\n",
    "**Decisión Final**: \n",
    "- Foco de clasificador: “alto éxito”\n",
    "- **SVM**: entrenar sobre 312 clases (cobertura ~75%).\n",
    "- **BERT**: entrenar sobre 430 clases (mínimo ~2000 muestras por clase; evaluación más estable).\n",
    "- Esto produce dos modelos comparables, ambos “de alta probabilidad de éxito”, pero con BERT cubriendo más taxonomía sin sacrificar tanto la calidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8757330",
   "metadata": {},
   "source": [
    "## Arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d6045",
   "metadata": {},
   "source": [
    "```text\n",
    "    Entrada: descripción del producto\n",
    "                ↓\n",
    "[Filtro IN/OUT — BERT binario compartido]\n",
    "                ↓ \n",
    "   ┌───────────────────────────────┐\n",
    "   ↓                               ↓\n",
    "[SVM multiclase]           [BERT multiclase] \n",
    "        ↓                          ↓\n",
    "   Código HS                  Código HS\n",
    "        ↓                          ↓\n",
    "            [Revisión Expeta]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07b527",
   "metadata": {},
   "source": [
    "## Modelo Filtro IN/OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo base para el filtro binario\n",
    "\n",
    "DF_NAME = \"data_df\" \n",
    "COL_TEXT = \"mercancia_descripcion\"  # columna con la descripción (texto)\n",
    "COL_CODE = \"partida_arancelaria_codigo\"  # columna con HS code (string/num)\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"  # alternativa: \"roberta-base\", \"xlm-roberta-base\"\n",
    "MAX_LENGTH = 64\n",
    "MAX_ROWS_FOR_FILTER = 400000  # ajuste según RAM/tiempo\n",
    "\n",
    "# Split: se hará split en dos etapas: train vs temp, luego val vs test\n",
    "TEST_SIZE = 0.2\n",
    "N_PER_CLASS = 2000\n",
    "VAL_SIZE = 0.10\n",
    "\n",
    "# IN por TOP_K clases más frecuentes\n",
    "TOP_K_IN = 430  # 312 para SVM, 430 para BERT.\n",
    "\n",
    "# Entrenamiento \n",
    "BATCH_TRAIN = 16\n",
    "BATCH_EVAL = 32\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "\n",
    "LR = 2e-5\n",
    "EPOCHS = 2\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_RATIO = 0.06\n",
    "\n",
    "TOKENIZERS_PARALLELISM = False\n",
    "set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9e1706",
   "metadata": {},
   "source": [
    "Construcción del set de clases \"IN\" (top-K o por cobertura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ba272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar_texto(text: str) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece90e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] TOP_K_IN={TOP_K_IN}\")\n",
    "filename_clases_in = \"clases_ins.csv\"\n",
    "path_clases_in = Path(DIR_LOG, filename_clases_in)\n",
    "df_in_top_k = globals()[DF_NAME].copy()\n",
    "\n",
    "# Normaliza tipos\n",
    "df_in_top_k[COL_TEXT] = df_in_top_k[COL_TEXT].astype(str).str.strip()\n",
    "df_in_top_k[COL_TEXT] = df_in_top_k[COL_TEXT].apply(preprocesar_texto)\n",
    "df_in_top_k[COL_CODE] = df_in_top_k[COL_CODE].astype(str).str.strip()\n",
    "df_in_top_k = df_in_top_k[df_in_top_k[COL_TEXT].str.len() > 0].copy()\n",
    "\n",
    "vc = df_in_top_k[COL_CODE].value_counts()\n",
    "clases_objetivo = vc.head(TOP_K_IN).index.tolist()\n",
    "\n",
    "print(f\"[INFO] IN classes: {len(clases_objetivo)} | cobertura aprox: {(vc.head(TOP_K_IN).sum()/vc.sum()):.4f}\")\n",
    "\n",
    "pd.Series(clases_objetivo, name=\"clases_objetivo\").to_csv(path_clases_in, index=False)\n",
    "print(f\"[OK] Guardado: {path_clases_in}\")\n",
    "\n",
    "df_in_top_k[\"label_in\"] = df_in_top_k[COL_CODE].isin(clases_objetivo).astype(int)\n",
    "print(df_in_top_k[\"label_in\"].value_counts(dropna=False))\n",
    "print(df_in_top_k.shape)\n",
    "print(df_in_top_k.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f0f015",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- TOP_K_IN=430 cubre 80.39% del universo: buen punto si para calidad y cobertura.\n",
    "- Distribución label_in: \n",
    "  - IN 4,119,753 (80.4%) vs OUT 1,005,272 (19.6%). \n",
    "  - Por el momento desbalanceado; si se entrena el filtro binario sin balanceo, tenderá a predecir IN.\n",
    "  - Tamaño final: 5,125,025 filas y 9 columnas (incluye len_descripcion y label_in)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5886e7",
   "metadata": {},
   "source": [
    "Limpieza y submuestreo con balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685b4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance dentro de IN + OUT 50/50\n",
    "\n",
    "df_clean = df_in_top_k.copy()\n",
    "df_clean[COL_TEXT] = df_clean[COL_TEXT].fillna(\"\").astype(str).str.strip()\n",
    "df_clean = df_clean[df_clean[COL_TEXT].str.len() > 0].copy()\n",
    "\n",
    "df_in = df_clean[df_clean[\"label_in\"] == 1]\n",
    "df_out = df_clean[df_clean[\"label_in\"] == 0]\n",
    "\n",
    "# Balancear IN por clase HS\n",
    "df_in_bal = df_in.groupby(COL_CODE, group_keys=False).apply(\n",
    "    lambda x: x.sample(min(len(x), N_PER_CLASS), random_state=SEED)\n",
    ")\n",
    "\n",
    "# Balancear OUT al total de IN balanceado\n",
    "df_out_bal = df_out.sample(n=min(len(df_out), len(df_in_bal)), random_state=SEED)\n",
    "\n",
    "df_bal = pd.concat([df_in_bal, df_out_bal]).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "print(\"[INFO] IN balanceado:\", len(df_in_bal))\n",
    "print(\"[INFO] OUT balanceado:\", len(df_out_bal))\n",
    "print(df_bal[\"label_in\"].value_counts())\n",
    "print(\"[INFO] Clases IN:\", df_in_bal[COL_CODE].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470e038b",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- Balance ok: 860k IN y 860k OUT.\n",
    "- 430 clases IN con ~2,000 muestras por clase (860k / 430).\n",
    "- Dataset final balanceado (1.72M filas) listo para split/entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a2f31f",
   "metadata": {},
   "source": [
    "Split train/val/test estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d631a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split por índices (menos copias)\n",
    "idx = df_bal.index.to_numpy()\n",
    "y = df_bal[\"label_in\"].to_numpy()\n",
    "\n",
    "idx_trainval, idx_test = train_test_split(\n",
    "    idx, test_size=TEST_SIZE, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "val_fraction_of_trainval = VAL_SIZE / (1 - TEST_SIZE)\n",
    "y_trainval = df_bal.loc[idx_trainval, \"label_in\"].to_numpy()\n",
    "\n",
    "idx_train, idx_val = train_test_split(\n",
    "    idx_trainval, test_size=val_fraction_of_trainval,\n",
    "    stratify=y_trainval, random_state=SEED\n",
    ")\n",
    "\n",
    "df_train = df_bal.loc[idx_train].copy()\n",
    "df_val   = df_bal.loc[idx_val].copy()\n",
    "df_test  = df_bal.loc[idx_test].copy()\n",
    "\n",
    "print(f\"[INFO] train={len(df_train):,} | val={len(df_val):,} | test={len(df_test):,}\")\n",
    "print(\"[INFO] Distribución label_in:\")\n",
    "print(\" - train:\", df_train[\"label_in\"].value_counts(normalize=True).to_dict())\n",
    "print(\" - val:  \", df_val[\"label_in\"].value_counts(normalize=True).to_dict())\n",
    "print(\" - test: \", df_test[\"label_in\"].value_counts(normalize=True).to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3daabd3",
   "metadata": {},
   "source": [
    "**Notas**:\n",
    "- El split generó:\n",
    "  - Tamaños consistentes con 80/10/10 aprox. sobre 1.72M filas.\n",
    "  - Distribución balanceada (50/50) en train/val/test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa7726",
   "metadata": {},
   "source": [
    "Dataset + Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "class InOutDataset(Dataset):\n",
    "    def __init__(self, df, text_col, label_col, tokenizer, max_length):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.text_col = text_col\n",
    "        self.label_col = label_col\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, list):\n",
    "            texts = self.df.loc[idx, self.text_col].astype(str).tolist()\n",
    "            labels = self.df.loc[idx, self.label_col].astype(int).tolist()\n",
    "            enc = self.tokenizer(\n",
    "                texts,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=False\n",
    "            )\n",
    "            enc[\"labels\"] = labels\n",
    "            return enc\n",
    "\n",
    "        text = str(self.df.at[idx, self.text_col])\n",
    "        label = int(self.df.at[idx, self.label_col])\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=False\n",
    "        )\n",
    "        enc[\"labels\"] = label\n",
    "        return enc\n",
    "\n",
    "\n",
    "train_ds = InOutDataset(df_train, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "val_ds = InOutDataset(df_val, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "test_ds = InOutDataset(df_test, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64e1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] tokenizer:\", MODEL_NAME)\n",
    "print(\"[INFO] max_length:\", MAX_LENGTH)\n",
    "\n",
    "train_ds = InOutDataset(df_train, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "val_ds = InOutDataset(df_val, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "test_ds = InOutDataset(df_test, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "\n",
    "print(\"[INFO] sizes -> train:\", len(train_ds), \"val:\", len(val_ds), \"test:\", len(test_ds))\n",
    "\n",
    "# Ejemplo rápido\n",
    "sample = train_ds[0]\n",
    "print(\"[INFO] sample keys:\", sample.keys())\n",
    "print(\"[INFO] sample label:\", sample[\"labels\"])\n",
    "print(\"[INFO] sample input_ids length:\", len(sample[\"input_ids\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12739441",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[INFO] sample text:\", df_train.iloc[0][COL_TEXT])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8980b",
   "metadata": {},
   "source": [
    "Modelo BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels=2, \n",
    "    id2label={0: \"OUT\", 1: \"IN\"}, \n",
    "    label2id={\"OUT\": 0, \"IN\": 1}\n",
    ")\n",
    "model.to(device)\n",
    "print(model)\n",
    "print(device)\n",
    "print(\"[INFO] num_labels:\", model.config.num_labels)\n",
    "print(\"[INFO] id2label:\", model.config.id2label)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"[INFO] params:\", f\"{num_params:,}\")\n",
    "print(\"[INFO] trainable:\", f\"{num_trainable:,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "print(\"MPS:\", torch.backends.mps.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f23c547",
   "metadata": {},
   "source": [
    "```python\n",
    "# Asegurar que train_ds sea InOutDataset\n",
    "train_ds = InOutDataset(df_train, COL_TEXT, \"label_in\", tokenizer, MAX_LENGTH)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "n_test = 1024\n",
    "sample_ds = Subset(train_ds, range(min(n_test, len(train_ds))))\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Subset pequeño para test rápido\n",
    "n_test = 512\n",
    "sample_ds = Subset(train_ds, range(min(n_test, len(train_ds))))\n",
    "\n",
    "batch_sizes = [4, 8, 12, 16, 24, 32, 48, 64, 96, 128]\n",
    "max_ok = None\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    try:\n",
    "        print(f\"[TEST] batch_size={bs} ...\", end=\"\")\n",
    "        loader = DataLoader(sample_ds, batch_size=bs, collate_fn=data_collator)\n",
    "        batch = next(iter(loader))\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            _ = model(**batch)\n",
    "        print(\" OK\")\n",
    "        max_ok = bs\n",
    "    except RuntimeError as e:\n",
    "        print(\" FAIL\")\n",
    "        print(\"Reason:\", e)\n",
    "        break\n",
    "\n",
    "print(\"[INFO] max batch size OK:\", max_ok)\n",
    "```\n",
    "\n",
    "```text\n",
    "[TEST] batch_size=4 ... OK\n",
    "[TEST] batch_size=8 ... OK\n",
    "[TEST] batch_size=12 ... OK\n",
    "[TEST] batch_size=16 ... OK\n",
    "[TEST] batch_size=24 ... OK\n",
    "[TEST] batch_size=32 ... OK\n",
    "[TEST] batch_size=48 ... OK\n",
    "[TEST] batch_size=64 ... OK\n",
    "[TEST] batch_size=96 ... OK\n",
    "[TEST] batch_size=128 ... OK\n",
    "[INFO] max batch size OK: 128\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c3aea",
   "metadata": {},
   "source": [
    "Entrenamiento BERT binario (Trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9554ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"transformers.__version__ =\", transformers.__version__)\n",
    "print(\"TrainingArguments module  =\", TrainingArguments.__module__)\n",
    "print(\"TrainingArguments file    =\", inspect.getsourcefile(TrainingArguments))\n",
    "print(\"TrainingArguments init sig=\", inspect.signature(TrainingArguments.__init__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7610f741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08216530",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=str(Path(DIR_MODELS) / \"tmp_inout\"),\n",
    "\n",
    "    eval_strategy=\"no\",     \n",
    "    save_strategy=\"no\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "\n",
    "    per_device_train_batch_size=BATCH_TRAIN,\n",
    "    per_device_eval_batch_size=BATCH_EVAL,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    warmup_ratio=WARMUP_RATIO,\n",
    "\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    \n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    "    remove_unused_columns=False,\n",
    "    seed=SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8653a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "print(trainer)\n",
    "print(\"[INFO] train_dataset:\", len(trainer.train_dataset))\n",
    "print(\"[INFO] eval_dataset:\", len(trainer.eval_dataset))\n",
    "print(\"[INFO] batch_size_train:\", training_args.per_device_train_batch_size)\n",
    "print(\"[INFO] batch_size_eval:\", training_args.per_device_eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fdc5f0",
   "metadata": {},
   "source": [
    "Calculo de steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1fb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps por época (aprox)\n",
    "train_steps_per_epoch = len(trainer.train_dataset) // (\n",
    "    training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps\n",
    ")\n",
    "eval_steps = len(trainer.eval_dataset) // training_args.per_device_eval_batch_size\n",
    "\n",
    "print(\"[INFO] train steps/epoch:\", train_steps_per_epoch)\n",
    "print(\"[INFO] eval steps:\", eval_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7f109",
   "metadata": {},
   "source": [
    "**Notas:**\n",
    "- train steps/epoch = 18,812: número de actualizaciones por época (tiempo por época).\n",
    "- eval steps = 1,343: número de batches en validación (determina cuánto tarda evaluar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c797f1a",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091aa80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evitar paralelismo que a veces rompe kernels en Mac\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" \n",
    "torch.set_num_threads(min(8, os.cpu_count() or 8))\n",
    "\n",
    "# Vaciar caches\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        torch.mps.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"[INFO] MPS available:\", torch.backends.mps.is_available())\n",
    "print(\"[INFO] CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be1255",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKUP_DIR = Path(DIR_MODELS) / \"bert_inout_ckpt_final\"\n",
    "TRAIN_OUT_PATH = BACKUP_DIR / \"train_output.json\"\n",
    "TRAIN_ARGS_PATH = BACKUP_DIR / \"training_args.json\"\n",
    "\n",
    "#  Ajustes de estabilidad para Mac \n",
    "if hasattr(trainer, \"args\") and trainer.args is not None:\n",
    "    # Evitar multiproceso en dataloaders\n",
    "    trainer.args.dataloader_num_workers = 0\n",
    "    trainer.args.dataloader_pin_memory = False\n",
    "\n",
    "    # Bajar eval batch para reducir peak de memoria (si eval ocurre)\n",
    "    if getattr(trainer.args, \"per_device_eval_batch_size\", None) is not None:\n",
    "        trainer.args.per_device_eval_batch_size = min(int(trainer.args.per_device_eval_batch_size), 16)\n",
    "\n",
    "    # Logging estable\n",
    "    trainer.args.disable_tqdm = False\n",
    "    trainer.args.report_to = \"none\"\n",
    "\n",
    "# Si el modelo lo permite: gradient checkpointing reduce memoria (a costa de tiempo)\n",
    "try:\n",
    "    trainer.model.gradient_checkpointing_enable()\n",
    "    trainer.model.config.use_cache = False  # importante para evitar uso extra de memoria\n",
    "    print(\"[INFO] gradient_checkpointing habilitado.\")\n",
    "except Exception as e:\n",
    "    print(\"[WARN] No se pudo habilitar gradient_checkpointing:\", e)\n",
    "\n",
    "\n",
    "# Limpieza preventiva\n",
    "gc.collect()\n",
    "if torch.backends.mps.is_available():\n",
    "    try:\n",
    "        torch.mps.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if BACKUP_DIR.exists():\n",
    "    print(\"[INFO] Modelo FINAL ya existe, cargando...\")\n",
    "    if (\"model\" in globals()) and (\"tokenizer\" in globals()):\n",
    "        print(\"[INFO] Reutilizando modelo/tokenizer ya cargados en memoria.\")\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(str(BACKUP_DIR), use_fast=True)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(str(BACKUP_DIR), low_cpu_mem_usage=True)\n",
    "\n",
    "    try:\n",
    "        trainer.model = model\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if TRAIN_OUT_PATH.exists():\n",
    "        with open(TRAIN_OUT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "            train_metrics = json.load(f)\n",
    "        print(\"[INFO] train metrics (loaded):\", train_metrics)\n",
    "\n",
    "else:\n",
    "    print(\"[INFO] Starting FINAL training...\")\n",
    "    print(\"[INFO] epochs:\", trainer.args.num_train_epochs)\n",
    "    print(\"[INFO] batch_train:\", trainer.args.per_device_train_batch_size)\n",
    "    print(\"[INFO] grad_accum:\", trainer.args.gradient_accumulation_steps)\n",
    "    print(\"[INFO] lr:\", trainer.args.learning_rate)\n",
    "    # --- Evitar picos: desactivar evaluación durante train y evaluar después ---\n",
    "    # Si usted tiene evaluation_strategy=\"epoch\" en training_args, esto provoca eval en cada epoch.\n",
    "    # Lo desactivamos solo para el train final (safe).\n",
    "    try:\n",
    "        trainer.args.evaluation_strategy = \"no\"\n",
    "        trainer.args.save_strategy = \"no\"  # evita guardados intermedios grandes\n",
    "        print(\"[INFO] evaluation_strategy='no' durante training (safe).\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    train_output = trainer.train()\n",
    "\n",
    "    print(\"[INFO] Training done.\")\n",
    "    print(\"[INFO] train_output.metrics:\", train_output.metrics)\n",
    "\n",
    "    # Guardar artefactos finales\n",
    "    BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    trainer.save_model(str(BACKUP_DIR))\n",
    "    tokenizer.save_pretrained(str(BACKUP_DIR))\n",
    "\n",
    "    with open(TRAIN_OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(train_output.metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    with open(TRAIN_ARGS_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(\n",
    "            {\n",
    "                \"bert_base\": getattr(tokenizer, \"name_or_path\", None),\n",
    "                \"max_length\": globals().get(\"MAX_LENGTH\", None),\n",
    "                \"num_train_epochs\": trainer.args.num_train_epochs,\n",
    "                \"per_device_train_batch_size\": trainer.args.per_device_train_batch_size,\n",
    "                \"per_device_eval_batch_size\": trainer.args.per_device_eval_batch_size,\n",
    "                \"gradient_accumulation_steps\": trainer.args.gradient_accumulation_steps,\n",
    "                \"learning_rate\": trainer.args.learning_rate,\n",
    "                \"weight_decay\": trainer.args.weight_decay,\n",
    "                \"warmup_ratio\": getattr(trainer.args, \"warmup_ratio\", None),\n",
    "                \"seed\": trainer.args.seed,\n",
    "                \"fp16\": getattr(trainer.args, \"fp16\", False),\n",
    "                \"dataloader_num_workers\": trainer.args.dataloader_num_workers,\n",
    "                \"gradient_checkpointing\": True,\n",
    "            },\n",
    "            f,\n",
    "            ensure_ascii=False,\n",
    "            indent=2\n",
    "        )\n",
    "\n",
    "    print(f\"[OK] Modelo FINAL guardado en: {BACKUP_DIR}\")\n",
    "    print(f\"[OK] Métricas guardadas en: {TRAIN_OUT_PATH}\")\n",
    "    print(f\"[OK] Training args guardados en: {TRAIN_ARGS_PATH}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mbb-cc66r-1-prj)",
   "language": "python",
   "name": "mbb-cc66r-1-prj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
